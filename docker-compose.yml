version: "latest"  # the only version where 'runtime' option is supported

services:
  test:
    image: tensorflow/tensorflow:latest-gpu
    # Make Docker create the container with NVIDIA Container Toolkit
    # You don't need it if you set 'nvidia' as the default runtime in
    # daemon.json.
    runtime: nvidia
    # the lines below are here just to test that TF can see GPUs
    entrypoint:
      - /usr/local/bin/python
      - -c
    command:
      - "import tensorflow as tf; import time;
         assert tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None), 'GPU not found';
         start = time.time();
         print(tf.reduce_sum(tf.random.normal([10, 1000, 1000])));
         end = time.time();
         print('Took', end - start, 'seconds');
         assert end - start < 0.2, 'Took more than 0.2 sec, typical max time is 0.15 sec';"

